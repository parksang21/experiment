{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.05)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "def cal_index(num_classes, y):\n",
    "        batch_size = y.size(0)\n",
    "        new_index = torch.randperm(batch_size).type_as(y)\n",
    "        newY = y[new_index]\n",
    "        mask = (newY == y)\n",
    "        while mask.any().item():\n",
    "            newY[mask] = torch.randint(0, num_classes, (torch.sum(mask),)).type_as(y)\n",
    "            mask = (newY == y)\n",
    "        return newY\n",
    "        \n",
    "class NoiseEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 channel_in:  int,\n",
    "                 channel_out: int,\n",
    "                 kernel_size: int,\n",
    "                 stride:      int,\n",
    "                 padding:     int,\n",
    "                 bias:        bool=False, \n",
    "                 num_classes: int=6,\n",
    "                 alpha: float=1.0):\n",
    "        \n",
    "        super(self.__class__, self).__init__()\n",
    "        self.conv = nn.Conv2d(channel_in, channel_out, kernel_size, stride, padding, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(channel_out)\n",
    "        self.bn_noise = nn.BatchNorm2d(channel_out)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        self.num_classes = num_classes\n",
    "        self.register_buffer('buffer', None)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_clean(self, x, y, class_mask):\n",
    "        newY = cal_index(self.num_classes, y)\n",
    "        x = self.conv(x)\n",
    "        self.cal_class_per_std(x, class_mask)\n",
    "        noise = torch.normal(mean=0, std=self.buffer[newY]).type_as(x)\n",
    "        x_n = x + self.alpha * noise\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x_n = self.bn(x_n)\n",
    "        x_n = self.activation(x_n)\n",
    "        return x, x_n, newY\n",
    "        \n",
    "    def forward_noise(self, x, newY):\n",
    "        x = self.conv(x)\n",
    "        x = x + self.alpha * torch.normal(mean=0, std=self.buffer[newY]).type_as(x)\n",
    "        x = self.bn_noise(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "    def cal_class_per_std(self, x, idxs):\n",
    "        std = []\n",
    "        for i in range(self.num_classes):\n",
    "            x_ = x[idxs[i]].clone().detach()\n",
    "            \n",
    "            std.append(x_.std(0))\n",
    "        self.buffer = torch.stack(std)\n",
    "\n",
    "class classifier32(nn.Module):\n",
    "    def __init__(self, num_classes=2, **kwargs):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.conv1 = NoiseEncoder(3,     64,    3, 1, 1, bias=False, num_classes=num_classes)\n",
    "        self.conv2 = NoiseEncoder(64,    64,    3, 1, 1, bias=False, num_classes=num_classes)\n",
    "        self.conv3 = NoiseEncoder(64,   128,    3, 2, 1, bias=False, num_classes=num_classes)\n",
    "        \n",
    "        self.conv4 = NoiseEncoder(128,  128,    3, 1, 1, bias=False, num_classes=num_classes)\n",
    "        self.conv5 = NoiseEncoder(128,  128,    3, 1, 1, bias=False, num_classes=num_classes)\n",
    "        self.conv6 = NoiseEncoder(128,  128,    3, 2, 1, bias=False, num_classes=num_classes)\n",
    "        \n",
    "        self.conv7 = NoiseEncoder(128,  128,    3, 1, 1, bias=False, num_classes=num_classes)\n",
    "        self.conv8 = NoiseEncoder(128,  128,    3, 1, 1, bias=False, num_classes=num_classes)\n",
    "        self.conv9 = NoiseEncoder(128,  128,    3, 2, 1, bias=False, num_classes=num_classes)\n",
    "        \n",
    "        self.fc = nn.Linear(128, num_classes + 1)\n",
    "        self.dr1 = nn.Dropout2d(0.2)\n",
    "        self.dr2 = nn.Dropout2d(0.2)\n",
    "        self.dr3 = nn.Dropout2d(0.2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.apply(weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l1 = self.block1(x)\n",
    "        l2 = self.block2(l1)\n",
    "        y = self.block3(l2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    def block1(self, x):\n",
    "        x = self.dr1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def block1_n(self, x, y):\n",
    "        class_mask = y.unsqueeze(0) == torch.arange(\n",
    "            self.num_classes).type_as(y).unsqueeze(1)\n",
    "        x = self.dr1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        clean, noise, newY = self.conv3.forward_clean(x, y, class_mask)\n",
    "        return clean, noise, newY\n",
    "    \n",
    "    def block2(self, x):\n",
    "        x = self.dr2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def block2_n(self, x, y):\n",
    "        class_mask = y.unsqueeze(0) == torch.arange(\n",
    "            self.num_classes).type_as(y).unsqueeze(1)\n",
    "        x = self.dr2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        clean, noise, newY = self.conv6.forward_clean(x, y, class_mask)\n",
    "        return clean, noise, newY\n",
    "\n",
    "    def block3(self, x):\n",
    "        x = self.dr3(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        logit = self.fc(x)\n",
    "        return logit\n",
    "    \n",
    "    def block3_(self, x):\n",
    "        x = self.dr3(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return x\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, padding=1, downsample=None, groups=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(inplanes, planes, kernel_size, stride=stride, padding=padding),\n",
    "            # nn.BatchNorm2d(planes),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes, kernel_size, padding=padding),\n",
    "            # nn.BatchNorm2d(planes),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.proj = nn.Conv2d(inplanes, planes, 1) if stride==2 else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        y = self.conv1(x)\n",
    "        y = self.conv2(y)\n",
    "        \n",
    "        identity = identity if self.proj is None else self.proj(identity)\n",
    "        y = y + identity\n",
    "        return y\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Generator\n",
    "    \"\"\"\n",
    "    def __init__(self, out_channel=1, n_filters=128, n_noise=512):\n",
    "        super(Generator, self).__init__()\n",
    "        # self.fc = nn.Linear(n_noise, 1024*4*4)\n",
    "        self.G = nn.Sequential(\n",
    "            ResidualBlock(128, 128, 3, 1, 1),\n",
    "            ResidualBlock(128, 128, 3, 1, 1),\n",
    "            ResidualBlock(128, 128, 3, 1, 1),\n",
    "#             ResidualBlock(128, 64),\n",
    "#             ResidualBlock(64, 64),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.G(x)\n",
    "        return out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Discriminator\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.D = nn.Sequential(\n",
    "#             nn.Conv2d(in_channel, 64, 3, padding=1), # (N, 64, 64, 64)\n",
    "#             ResidualBlock(64, 128),\n",
    "#             nn.AvgPool2d(3, 2, padding=1), # (N, 128, 32, 32)\n",
    "#             ResidualBlock(128, 256),\n",
    "#             nn.AvgPool2d(3, 2, padding=1), # (N, 256, 16, 16)\n",
    "#             ResidualBlock(256, 512),\n",
    "#             nn.AvgPool2d(3, 2, padding=1), # (N, 512, 8, 8)\n",
    "#             ResidualBlock(512, 1024),\n",
    "#             nn.AvgPool2d(3, 2, padding=1) # (N, 1024, 4, 4)\n",
    "            ResidualBlock(128, 128, 3, 1, 1),\n",
    "            ResidualBlock(128, 128, 3, 1, 1),\n",
    "            nn.Conv2d(128, 128, 3, 2, 1),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        self.fc = nn.Linear(128, 1) # (N, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        h = self.D(x)\n",
    "        h = h.view(B, -1)\n",
    "        y = self.fc(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'experiment/log/FG/cifar10_s0/182'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experiment/log/FG/cifar10_s0/182/epoch=299-step=35399.ckpt',\n",
       " 'experiment/log/FG/cifar10_s0/182/FG.py',\n",
       " 'experiment/log/FG/cifar10_s0/182/wandb']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(path + \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = torch.load(path+'/epoch=299-step=35399.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
